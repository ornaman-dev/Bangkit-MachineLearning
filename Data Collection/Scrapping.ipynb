{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collecting\n",
    "Collect plant images from various sites in the internet (Google images/Bing) and automate this task by making a script using Python "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Automate Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.81M/6.81M [00:01<00:00, 3.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Download driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping(links,file_name,num_files):\n",
    "    \"\"\"\n",
    "        Procedur to retrieve image from the internet to the local file\n",
    "\n",
    "        Args:\n",
    "            links : links to retrieve image from\n",
    "            file_name : file name for the image to be saved\n",
    "            num_files : number of image to retrieve\n",
    "    \"\"\"\n",
    "\n",
    "    #Get sites links\n",
    "    driver.get(links)\n",
    "\n",
    "    # Scroll to bottom page\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    # Wait the page to load\n",
    "    time.sleep(3)\n",
    "\n",
    "    #Find the image ref and store it in the variable\n",
    "    imgResults = driver.find_elements(By.XPATH,\"//img[contains(@class,'rg_i Q4LuWd') or contains(concat(' ', normalize-space(@class), ' '), ' mimg ')]\") #Scrap from google images or bing images\n",
    "    src = []\n",
    "    for img in imgResults:\n",
    "        src.append(img.get_attribute('src'))\n",
    "\n",
    "    #Request the files and save it into local files\n",
    "    for i in range(num_files):    \n",
    "        urllib.request.urlretrieve(str(src[i]),\"../RawDatasets/{}/{}{}.jpg\".format(file_name,file_name,i))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrap from bing images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapping(links=\"https://www.bing.com/images/search?q=agglonema&form=HDRSC3&first=1\",file_name=\"Agglonema\",num_files=80)                  # Agglonema\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=spider+plant&form=HDRSC3&first=1\",file_name=\"Lili Paris\",num_files=80)              # Lili Paris\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=alocasia&form=HDRSC3&first=1\",file_name=\"Alocasia\",num_files=80)                    # Alocasia\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=+Sansevieria&form=HDRSC3&first=1\",file_name=\"Lidah Mertua\",num_files=80)            # Lidah Mertua\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=Monstera+&form=HDRSC3&first=1\",file_name=\"Janda Bolong\",num_files=80)               # Janda Bolong\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=Anthurium+plowmanii&form=HDRSC3&first=1\",file_name=\"Gelombang Cinta\",num_files=80)  # Gelombang Cinta\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=Adiantum&form=HDRSC3&first=1\",file_name=\"Suplir\",num_files=80)                      # Suplir\n",
    "scrapping(links=\"https://www.bing.com/images/search?q=syzygium+myrtifolium+&form=HDRSC3&first=1\",file_name=\"Pucuk Merah\",num_files=80)    # Pucuk Merah\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrap from google images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapping(\"https://www.google.com/search?q=Anthurium+plowmanii&rlz=1C1ONGR_enID973ID973&hl=en-US&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi947zJzPb-AhV22TgGHYh7A2kQ_AUoAXoECAEQAw&biw=1536&bih=754&dpr=1.25\",\"Gelombang Cinta\",num_files=200)\n",
    "scrapping(\"https://www.google.com/search?q=suplir+tanaman+hias&tbm=isch&ved=2ahUKEwjH8aCWnPf-AhUL_TgGHUzqDfkQ2-cCegQIABAA&oq=suplir+tanaman+hias&gs_lcp=CgNpbWcQAzIFCAAQgAQyBQgAEIAEMgYIABAIEB4yBggAEAgQHjIGCAAQCBAeMgYIABAIEB4yBggAEAgQHjIGCAAQCBAeOgQIIxAnOgQIABAeULcUWNwrYIUtaANwAHgAgAGSAYgBqAqSAQQxNS4ymAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=ehdiZMfMO4v64-EPzNS3yA8\",\"Suplir\",num_files=200)\n",
    "scrapping(\"https://www.google.com/search?q=syzygium+oleana&tbm=isch&ved=2ahUKEwir7Lqaq_f-AhVAzXMBHVz3Am4Q2-cCegQIABAA&oq&gs_lcp=CgNpbWcQARgAMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnMgcIIxDqAhAnOgQIIxAnOgUIABCABFDeA1jeA2CiDWgBcAB4AIABQ4gBQ5IBATGYAQCgAQGqAQtnd3Mtd2l6LWltZ7ABCsABAQ&sclient=img&ei=PidiZKvVE8Caz7sP3O6L8AY&bih=754&biw=1488\",\"Pucuk Merah\",num_files=200)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data**\n",
    "\n",
    "Split the data into train,test,and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1697 files [00:08, 211.99 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio('RawDataset', output=\"../Dataset\", seed=42, ratio=(0.7,0.15,0.15), group_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
